import numpy as np
from sklearn.neural_network import MLPRegressor
from sklearn.metrics import mean_squared_error
from sklearn.exceptions import ConvergenceWarning
import warnings

# Dummy training and validation data (replace with your actual data)
X_train = np.random.rand(100, 5)
y_train = np.random.rand(100)
X_valid = np.random.rand(20, 5)
y_valid = np.random.rand(20)

# Define the objective function
def objective_function(params):
    # Create neural network with given parameters
    nn = MLPRegressor(hidden_layer_sizes=params['hidden_layer_sizes'],
                      activation=params['activation'],
                      solver=params['solver'],
                      learning_rate_init=params['learning_rate'],
                      max_iter=params['max_iter'])
    
    # Train neural network
    with warnings.catch_warnings():
        warnings.filterwarnings("ignore", category=ConvergenceWarning)
        nn.fit(X_train, y_train)
    
    # Predict using trained neural network
    y_pred = nn.predict(X_valid)
    
    # Calculate mean squared error
    mse = mean_squared_error(y_valid, y_pred)
    
    return mse

# Define the genetic algorithm parameters
population_size = 100
mutation_rate = 0.1
crossover_rate = 0.8
generations = 10

def genetic_algorithm():
    population = initialize_population()
    for generation in range(generations):
        population = evolve_population(population)
        # Optionally, you can add code to monitor the progress
        # For example, you could print the best individual of each generation
        best_individual = min(population, key=lambda x: objective_function(x))
        print(f"Generation {generation+1}: Best MSE = {objective_function(best_individual)}")
    # After the specified number of generations, return the best individual
    best_individual = min(population, key=lambda x: objective_function(x))
    return best_individual


# Initialize population with random parameters
def initialize_population():
    population = []
    for _ in range(population_size):
        individual = {
            'hidden_layer_sizes': tuple(np.random.randint(5, 20, size=2)),
            'activation': np.random.choice(['identity', 'logistic', 'tanh', 'relu']),
            'solver': np.random.choice(['lbfgs', 'sgd', 'adam']),
            'learning_rate': np.random.uniform(0.0001, 0.01),
            'max_iter': np.random.randint(100, 1000)
        }
        population.append(individual)
    return population

# Evolution process: selection, crossover, and mutation
def evolve_population(population):
    next_generation = []
    for _ in range(population_size):
        parent1, parent2 = selection(population)
        offspring = crossover(parent1, parent2)
        offspring = mutation(offspring)
        next_generation.append(offspring)
    return next_generation

# Select individuals from population for crossover
def selection(population):
    selected = np.random.choice(population, size=2, replace=False)
    return selected[0], selected[1]

# Perform crossover between two individuals
def crossover(parent1, parent2):
    child = {}
    for key in parent1:
        if np.random.rand() < crossover_rate:
            child[key] = parent1[key]
        else:
            child[key] = parent2[key]
    return child

# Mutate an individual
def mutation(individual):
    for key in individual:
        if np.random.rand() < mutation_rate:
            if key == 'hidden_layer_sizes':
                individual[key] = tuple(np.random.randint(5, 20, size=2))
            elif key == 'activation':
                individual[key] = np.random.choice(['identity', 'logistic', 'tanh', 'relu'])
            elif key == 'solver':
                individual[key] = np.random.choice(['lbfgs', 'sgd', 'adam'])
            elif key == 'learning_rate':
                individual[key] = np.random.uniform(0.0001, 0.01)
            elif key == 'max_iter':
                individual[key] = np.random.randint(100, 1000)
    return individual

# Run genetic algorithm four times to get four different outputs
for i in range(2):
    print(f"Run {i+1}")
    best_params = genetic_algorithm()
    print("Best parameters:", best_params)
    print()
